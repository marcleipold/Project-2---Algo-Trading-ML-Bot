{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import alpaca_trade_api as tradeapi\n",
    "from alpaca.data.historical import CryptoHistoricalDataClient\n",
    "from alpaca.data.requests import CryptoBarsRequest\n",
    "from alpaca.data.timeframe import TimeFrame\n",
    "from finta import TA\n",
    "from finta.utils import resample_calendar\n",
    "import json\n",
    "import hvplot.pandas\n",
    "import holoviews as hv\n",
    "import panel as pn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from pandas.tseries.offsets import DateOffset\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "pn.extension()\n",
    "hv.extension('bokeh')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the crypto client\n",
    "client = CryptoHistoricalDataClient()\n",
    "# Setting a start date and end date\n",
    "#start_date = pd.Timestamp('2020-01-01', tz='America/New_York').isoformat()\n",
    "#end_date = pd.Timestamp('2023-01-01', tz='AMerica/New_York').isoformat()\n",
    "# Setting the tickers\n",
    "#ticker = ['BTC/USD']\n",
    "\n",
    "# Setting timeframe to '4Hour' for Alpaca API\n",
    "#timeframe = '4Hour'\n",
    "\n",
    "# Getting current ohlcv for BTC/USD\n",
    "request_params = CryptoBarsRequest(\n",
    "    symbol_or_symbols=['BTC/USD'],\n",
    "    timeframe=TimeFrame.Hour,\n",
    "    start='2020-01-01 00:00:00',\n",
    "    end='2023-01-01 00:00:00'\n",
    ")\n",
    "\n",
    "# Retreiving the $ hourly bars for BTC/USD\n",
    "btc_bars_48months = client.get_crypto_bars(request_params)\n",
    "\n",
    "# Converting to a DataFrame\n",
    "btc_bars_48months.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting json to a dataframe\n",
    "btc_bars_48months_df = btc_bars_48months.df\n",
    "# Dropping columns\n",
    "ohlcv_df  = btc_bars_48months_df.drop(columns=['trade_count','vwap'])\n",
    "# Renaming the 'timestamp' column to the 'date' column and setting it as an index\n",
    "ohlcv_df = ohlcv_df.reset_index()\n",
    "ohlcv_df['date'] = ohlcv_df['timestamp']\n",
    "ohlcv_df = ohlcv_df.drop(columns=['timestamp','symbol'])\n",
    "ohlcv_df.set_index('date', drop=True, inplace=True)\n",
    "# Making the df into a csv file\n",
    "ohlcv_df.to_csv('ohlcv_BTC.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Now I'm ready to manipulate the dataframe to build new columns like an RSI, RSI SMA and volume SMA.\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the csv to a df\n",
    "ohlcv_df = pd.read_csv(\n",
    "    Path('./Resources/ohlcv_BTC.csv'),\n",
    "    index_col='date',\n",
    "    infer_datetime_format=True,\n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Resampling the df to be 4hr candles\n",
    "four_hr_ohlcv = resample_calendar(ohlcv_df, '4h')\n",
    "four_hr_ohlcv.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting out my signals dataframe\n",
    "signals_df = four_hr_ohlcv.loc[:,['close']]\n",
    "# Generating returns from the BTC close prices using pct_change\n",
    "signals_df['Actual_Returns'] = signals_df['close'].pct_change().dropna()\n",
    "signals_df['Signal'] = 0.0\n",
    "signals_df.loc[(signals_df['Actual_Returns'] >= 0), 'Signal'] = 1\n",
    "signals_df.loc[(signals_df['Actual_Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "(1 + signals_df[['Actual_Returns']]).cumprod().hvplot()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding more indicators to the sisgnals_df\n",
    "signals_df['RSI14'] = TA.RSI(four_hr_ohlcv,14)\n",
    "signals_df.dropna()\n",
    "# Checking the RSI plot\n",
    "RSI63 = signals_df['RSI14'].hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the volume SMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# making the sma  rolling window for volume\n",
    "volume_sma = 3\n",
    "signals_df['volume'] = four_hr_ohlcv['volume']\n",
    "\n",
    "# making the sma based on the rolling window for volume\n",
    "signals_df['Volume_SMA_7'] = signals_df['volume'].rolling(window=volume_sma).mean()\n",
    "signals_df.dropna()\n",
    "\n",
    "# Checking the Volume SMA plot\n",
    "Volume_SMA_7 = signals_df['Volume_SMA_7'].hvplot(kind='line')\n",
    "Volume = signals_df['volume'].hvplot.bar()\n",
    "display(Volume) \n",
    "display(Volume_SMA_7)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making the RSI SMA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the window for the RSI SMA\n",
    "RSI_SMA = 7\n",
    "\n",
    "# Making the RSI SMA based on the rolling window\n",
    "signals_df['RSI_SMA_7'] = signals_df['RSI14'].rolling(window=RSI_SMA).mean()\n",
    "signals_df.dropna()\n",
    "\n",
    "RSI_SMA_7 = signals_df['RSI_SMA_7'].hvplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting bot indicators for review\n",
    "RSI63 * RSI_SMA_7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling the df\n",
    "signals_df.sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a signal for the actual strategy\n",
    "signals_df['A1_Strategy_Signal'] = 0.0\n",
    "\n",
    "signals_df['A1_Strategy_Signal'] = np.where((signals_df['RSI14'] > signals_df['RSI_SMA_7']) & (signals_df['volume'] > signals_df['Volume_SMA_7']),\n",
    "                                1, np.where((signals_df['RSI14'] < signals_df['RSI_SMA_7']) & (signals_df['volume'] < signals_df['Volume_SMA_7']), -1, 0)\n",
    ")\n",
    "\n",
    "signals_df['A1_Strategy_Signal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see how many buy signals compared to sell signals\n",
    "signals_df['A1_Strategy_Signal'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the df\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the MACD indicator\n",
    "MACD_df = TA.MACD(four_hr_ohlcv)\n",
    "MACD_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the indicators to the signals df\n",
    "signals_df['MACD'] = MACD_df['MACD']\n",
    "signals_df['SIGNAL'] = MACD_df['SIGNAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the signals df for the new indicators\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Squeeze momentum indicator and adding it to the signals df\n",
    "SQZMI_df = TA.SQZMI(four_hr_ohlcv)\n",
    "signals_df['SQZMI'] = SQZMI_df\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the ADX indicator and adding it to the signals df\n",
    "ADX_df = TA.ADX(four_hr_ohlcv)\n",
    "signals_df['ADX'] = ADX_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the df for the new indicator\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Chandelier indicator, used for stop losses based on the average true range(ATR)\n",
    "Chandelier_df = TA.CHANDELIER(four_hr_ohlcv)\n",
    "signals_df['short_stop'] = Chandelier_df['Short.']\n",
    "signals_df['long_stop'] = Chandelier_df['Long.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing df\n",
    "signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the df\n",
    "signals_df.hvplot(\n",
    "    height=500,\n",
    "    width=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function that calls a set of functions to be created on any df\n",
    "def indicators(df, sma, rsi, macd_fast, macd_slow, macd_signal, squeeze):\n",
    "\n",
    "    df['SMA_20'] = TA.SMA(df, sma)\n",
    "    df['RSI_14'] = TA.RSI(df, rsi)\n",
    "    MACD = TA.MACD(df, macd_fast,macd_slow,macd_signal,'close', adjust=True)\n",
    "    df['MACD'] = MACD['MACD']\n",
    "    df['MACD_Signal'] = MACD['SIGNAL']\n",
    "    df['MACD_Histogram'] = df['MACD'] - df['MACD_Signal']\n",
    "    df['Squeeze'] = TA.SQZMI(df, squeeze)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that defines our buy/sell strategy fopr the trading bot\n",
    "def buy_sell_signals(df, sma_window=20, rsi_window=14, macd_fast=12, macd_slow=26, macd_signal=9, squeeze_window=20):\n",
    "    \n",
    "    # Buy signal\n",
    "    df['signal'] = 0\n",
    "    df.loc[(df['RSI_14'] < 30) & (df['MACD_Histogram'] > 0) & (df['Squeeze'] == False), 'signal'] = 1\n",
    "\n",
    "    # Sell signal\n",
    "    df.loc[(df['RSI_14'] > 70) & (df['MACD_Histogram'] < 0) & (df['Squeeze'] == True), 'signal'] = -1\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the indicator function\n",
    "\n",
    "indicator_signals_df = indicators(four_hr_ohlcv,20,14,12,26,9,20)\n",
    "indicator_signals_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_signals_df['MACD_buy/sell'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_signals_df['Actual_Returns'] = indicator_signals_df['close'].pct_change().dropna()\n",
    "indicator_signals_df['Signal'] = 0.0\n",
    "indicator_signals_df.loc[(indicator_signals_df['Actual_Returns'] >= 0), 'Signal'] = 1\n",
    "indicator_signals_df.loc[(indicator_signals_df['Actual_Returns'] < 0), 'Signal'] = -1\n",
    "\n",
    "(1 + indicator_signals_df[['Actual_Returns']]).cumprod().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACD = hv.Curve(indicator_signals_df,'date','MACD').opts(\n",
    "    title='MACD',\n",
    "    height=400,\n",
    "    width=600,\n",
    "    active_tools=['pan'],\n",
    "    ylim=(0,1000) \n",
    ")\n",
    "MACD_S = hv.Curve(indicator_signals_df,'date','MACD_Signal').opts(\n",
    "    title='MACD',\n",
    "    height=400,\n",
    "    width=600,\n",
    "    active_tools=['pan'],\n",
    "    ylim=(0,1000) \n",
    ")\n",
    "MACD_Histogram = hv.Bars(indicator_signals_df,['date','MACD_Histogram']).opts(\n",
    "    title='MACD',\n",
    "    stacked=False,\n",
    "    multi_level=False,\n",
    "    height=400,\n",
    "    width=600,\n",
    "    active_tools=['pan'],\n",
    "    ylim=(0,1000) )\n",
    "\n",
    "curve_rend = hv.render(MACD)\n",
    "curve_rend_2 = hv.render(MACD_S)\n",
    "rend = hv.render(MACD_Histogram)\n",
    "curve_rend.x_range=rend.x_range\n",
    "curve_rend_2.x_range=rend.x_range\n",
    "rend.renderers+=curve_rend.renderers\n",
    "pn.pane.Bokeh(rend).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Section\n",
    "### Using Ada Boost to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicator_signals_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(indicator_signals_df.dtypes[indicator_signals_df.dtypes=='bool'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_variables = ['Squeeze']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "# Encode the categorcal variables using OneHotEncoder\n",
    "encoded_data = enc.fit_transform(indicator_signals_df[categorical_variables])\n",
    "# Create a DataFrame with the encoded variables\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_data,\n",
    "    columns=enc.get_feature_names(categorical_variables)\n",
    ")\n",
    "# Review the DataFrame\n",
    "encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(indicator_signals_df.dtypes[indicator_signals_df.dtypes=='float64'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the numerical variables from the original DataFrame to the one-hot encoding DataFrame\n",
    "numerical_variables=[]\n",
    "numerical_variables_df = pd.DataFrame(\n",
    "    indicator_signals_df,\n",
    "    columns=(numerical_variables)\n",
    ")\n",
    "\n",
    "joined_encoded_df = pd.concat([encoded_df, numerical_variables_df],axis=1)\n",
    "\n",
    "# Review the DataFrame\n",
    "joined_encoded_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating training and testing data\n",
    "y = joined_encoded_df['']\n",
    "\n",
    "X = joined_encoded_df.drop(columns=(''))\n",
    "# Reviewing testing data\n",
    "display(y.head())\n",
    "display(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features and target sets into training and testing datasets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "# Fitting the scaler to the features traing dataset\n",
    "X_scaler - scaler.fit(X_train)\n",
    "# Fitting the scaled dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaled.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating the Deep Neural Network\n",
    "Using a Deep Neural network to train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the number of inputs\n",
    "number_input_features = len(X_train.iloc[0])\n",
    "\n",
    "# Reviewing the number of features\n",
    "display(number_input_features)\n",
    "\n",
    "# Defining number of outputs\n",
    "number_output_neurons = 1\n",
    "\n",
    "# Defining the number of hidden nodes for the first layer\n",
    "hidden_nodes_layer1 = np.ceil(np.sqrt(number_input_features * number_output_nuerons))\n",
    "\n",
    "# Reviewing the number of hidden nodes\n",
    "display(hidden_nodes_layer1)\n",
    "\n",
    "# Defining the number of hidden nodes for the second layer\n",
    "hidden_nodes_layer2 = np.ceil(np.sqrt(hidden_nodes_layer1 * number_output_nuerons))\n",
    "\n",
    "# Reviewing the number of hidden nodes in the second layer\n",
    "display(hidden_nodes_layer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Sequential model instance\n",
    "nn = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the first layer\n",
    "nn.add(\n",
    "    Dense(\n",
    "        units=hidden_nodes_layer1,\n",
    "        activation='relu',\n",
    "        input_dim=number_input_features\n",
    "    )\n",
    ")\n",
    "\n",
    "# Adding the second layer\n",
    "nn.add(\n",
    "    Dense(\n",
    "        units=hidden_nodes_layer2,\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "# Adding the output layer\n",
    "nn.add(\n",
    "    Dense(\n",
    "        units=1,\n",
    "        activation='sigmoid'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewing the Sequential model summary\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the Sequential model\n",
    "nn.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the model with 100 epochs and the training data\n",
    "nn.model=nn.fit(X_train, y_train, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiating the Ada Boost Machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate the model instance\n",
    "ada_boost_model = AdaBoostClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the training data\n",
    "ada_boost_model = ada_boost_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Use the testing dataset to generate the predictions for the new model\n",
    "ada_boost_pred = ada_boost_model.predict(X_test_scaled)\n",
    "\n",
    "# Review the model's predicted values\n",
    "ada_boost_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a classification report to evaluate the model using the predictions and testing data\n",
    "ada_testing_report = classification_report(y_test, ada_boost_pred)\n",
    "# Print the classification report\n",
    "print(ada_testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a predictions DataFrame\n",
    "ada_predictions_df = pd.DataFrame(index=X_test.index)\n",
    "# Add the SVM model predictions to the DataFrame\n",
    "ada_predictions_df['Predicted'] = ada_boost_pred\n",
    "# Add the actual returns to the DataFrame\n",
    "ada_predictions_df['Actual Returns'] = indicator_signals_df['Actual Returns']\n",
    "# Add the strategy returns to the DataFrame\n",
    "ada_predictions_df['ADA Strategy Returns'] = indicator_signals_df['Actual Returns'] * ada_predictions_df['Predicted']\n",
    "# Review the DataFrame\n",
    "display(ada_predictions_df.head())\n",
    "display(ada_predictions_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the actual returns versus the strategy returns\n",
    "(1 + ada_predictions_df[['Actual Returns','ADA Strategy Returns']]).cumprod().plot()\n",
    "\n",
    "# MAking a stand alone plot for the ADA Model\n",
    "ADA_plot = (1 + ada_predictions_df[['ADA Strategy Returns']]).cumprod().hvplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 01:53:17) \n[Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "996ffda76004d767ccbaaba7e2437ee3b45ec97388b0612ddf8c69ff1d3b8680"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
